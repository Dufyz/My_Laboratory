# Bibliotecas que serão utilizadas 

import pandas as pd
import numpy as np 
import collections
import matplotlib.pyplot as plt
import seaborn as sns

from numpy.random import seed

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.dummy import DummyClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

# Cursores

seed = 57
np.random.seed(seed)

# Modelos 

model_svc = SVC()
model_lsvc = LinearSVC(max_iter= 100)
model_forest =  RandomForestClassifier()
model_dummy = DummyClassifier()
StandardScaler = StandardScaler()

# Dataframes que serão utilizados

df_raw = pd.read_csv("G:\Meu Drive\My Repositories\My Laboratory\Jupyter Lab\databases\datasets\\cancer.csv")
df = df_raw

# Alterando o dataframe 

x = []

for c in range(1,34):

    old_name = str(f'exame_{c}')
    new_name = str(f'exam_{c}')

    rename_columns = {
        old_name: new_name
    }

    df = df.rename(columns= rename_columns)

    if c == 33:
        rename_columns = {
        'id': 'ID',
        'diagnostico': 'result',
        }

        df = df.rename(columns= rename_columns)
        #df['result'] = df['result'].map({'B': 0, 'M': 1})

        df = df.dropna()

    x.append(new_name)

df.head()


# Dividindo dados de treino e teste e reescalando 

df_raw_x = df[x]
df_raw_y = df['result']

#StandardScaler = StandardScaler.fit(df_raw_x)
#df_x = StandardScaler.transform(df_raw_x)
#df_y = df_raw_y
df_x = df_raw_x
df_y = df_raw_y

train_x, test_x, train_y, test_y = train_test_split(df_x, df_y, test_size= 0.6, stratify= df_y)

# Listas para armazenar os resultados dos nossos modelos

grade_svc = []
grade_lsvc = []
grade_forest = []
grade_dummy = []

# Looping para mediar várias vezes nossos modelos para obter uma média de desempenho 

for  c in range(1):

    # Treinando nossos modelos

    model_svc.fit(train_x, train_y)
    #model_lsvc.fit(train_x, train_y)
    model_forest.fit(train_x, train_y)
    model_dummy.fit(train_x, train_y)

    predict_svc = model_svc.predict(test_x)
    #predict_lsvc = model_lsvc.predict(test_x)
    predict_forest = model_forest.predict(test_x)
    predict_dummy = model_dummy.predict(test_x)

    # Medindo nosso modelos

    accuracy_svc = accuracy_score(predict_svc, test_y) * 100
    #accuracy_lsvc = accuracy_score(predict_lsvc, test_y) * 100
    accuracy_forest = accuracy_score(predict_forest, test_y) * 100
    accuracy_dummy = accuracy_score(predict_dummy, test_y) * 100

    # Armazenando nossas medições

    grade_svc.append(accuracy_svc)
    #grade_lsvc.append(accuracy_lsvc)
    grade_forest.append(accuracy_forest)
    grade_dummy.append(accuracy_dummy)


grade_svc = np.mean(grade_svc)
#grade_lsvc = np.mean(grade_lsvc)
grade_forest = np.mean(grade_forest)
grade_dummy = np.mean(grade_dummy)

print(f'A taxa de acerto do SVC foi de %.1f' % grade_svc)
#print(f'A taxa de acerto do LSVC foi de %.1f' % grade_lsvc)
print(f'A taxa de acerto do Forest foi de %.1f' % grade_forest)
print(f'A taxa de acerto do Dummy foi de %.1f' % grade_dummy)

# Adaptando nossos dados para visualização 

scaler = StandardScaler.fit(df_x)
df_x_plot = scaler.transform(df_x)
df_x_plot = pd.DataFrame(data= df_x_plot, columns= df_raw_x.keys())

df_plot = pd.concat([df_y, df_x_plot], axis= 1)
df_plot = pd.melt(df_plot, id_vars= 'result', value_name= 'value', var_name= 'exams')

# Visualização dos nossos dados 

plt.figure(figsize=(40,15))
plt.xticks(rotation = 90)

plot_01 = sns.violinplot(x = "exams", y = "value", 
               hue = "result", data = df_plot, split= True)
            

plot_01